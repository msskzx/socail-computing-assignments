{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hJAumQyI45Cg"
   },
   "source": [
    "# Social Computing/Social Gaming - Summer 2021\n",
    "# Exercise Sheet 5 - Hate Speech\n",
    "Online hate speech is a large scale phenomenon that gained more and more traction in modern society in recent years. Violence attributed to online hate speech has increased worldwide. The same technology that allows social media to galvanize activist movements and NGOs can be used by hate/crime groups seeking to organize and recruit. It also allows conspiration theorists to reach audiences far broader than their core community. It is time – now more than ever –  to put systems in place that make sure social media is not used as a tool to conduct criminal activities. Fortunately, modern technology allows us to do just that.\n",
    "\n",
    "In this exercise sheet, we will attempt to accurately and automatically detect two instances of hate speech in Twitter: sexism and racism. The first step in this process will be to prepare the data before it is fed to the model. We do this with the help of the Universal Sentence Encoder, which is explained in more detail later. Additionally, we also need to encode the labels and split the data.\n",
    "\n",
    "We then take two different approaches in classifying the data. In other words, we will create, train, evaluate and compare two models. One of them is purely based on text (the Base Model) and the other also takes the social context of the users into account (the Social Model)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3oiBPS0r45Co"
   },
   "source": [
    "## Why Twitter?\n",
    "Hate crimes are communicative acts, often provoked by events that incite retribution in a targeted group. The continued growth of online social networks and micro-blogging Web services, such as Twitter, enable an extensive and near real-time data source through which the analysis of hateful and antagonistic responses to “trigger” events can be undertaken. Such data affords researchers with the possibility to measure the online social mood and emotion following large-scale, disruptive, and emotive events. Twitter is a defensible and logical source of data for such analysis given that users of social media are more likely to express emotional content due to deindividuation (anonymity, lack of self-awareness in groups, disinhibition) [1]."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UhxfaKOZfEBN"
   },
   "source": [
    "## Task 5.0: The Data\n",
    "For this, we have picked the dataset of Waseem and Hovy [2], in a slightly modified version. The collection originally contained 16,914 labeled tweets, however some of them are not accessible via Twitter API anymore. As a consequence, the dataset now contains 16,849 tweets divided in the following categories: 3,378 *sexism*, 1,970 *racism* and 11,501 *neither*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Bnz1j9RsBjiu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6LnDiJ1UnYs9"
   },
   "outputs": [],
   "source": [
    "# Reads the data set from a .csv file\n",
    "data = pd.read_csv('tweets.csv', low_memory=False)\n",
    "data = data.astype(str)\n",
    "\n",
    "# This drop operation is necessary because of an inconsistency in the dataset\n",
    "data = data.drop([3343, 3344])\n",
    "data = data[['text', 'label']]\n",
    "\n",
    "# We need to do a unique and precise reordering to match with graph information later on\n",
    "unique_tweets, indices = np.unique(data['text'].to_numpy(), return_index=True)\n",
    "ordered_labels = data['label'].to_numpy()[indices]\n",
    "data = pd.DataFrame(np.stack((unique_tweets, ordered_labels), axis=1), columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_ztw1QebAK0",
    "outputId": "ce3a10af-c304-4366-d070-1f1c4d40865c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TWEETS: 16849, RACIST: 1970, SEXIST: 3378, NEITHER: 11501\n"
     ]
    }
   ],
   "source": [
    "# See the summary of the dataset's content\n",
    "\n",
    "print(\"TOTAL TWEETS: {}, RACIST: {}, SEXIST: {}, NEITHER: {}\".\\\n",
    "      format(len(data), len(data[data[\"label\"] == 'racism']), len(data[data[\"label\"] == 'sexism']), len(data[data['label'] == 'none'])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PgCD_Y9o45Cu"
   },
   "source": [
    "## Task 5.1: Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0Xta8UAMEe0E"
   },
   "source": [
    "### a) Encode the labels\n",
    "In order for [PyTorch](https://pytorch.org) to work with the labels, they need to have a specific format. Strings need to be replaced by numbers with an according mapping.\n",
    "\n",
    "Map the labels from the `label_mapping = ['sexism' 'none' 'racism']` to a numeric vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P849Lj_K520h"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4VAbuqeEXok",
    "outputId": "9cc4eb3b-7bd3-42d5-b2e0-31d3a98278c9"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "toArray not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m encoder \u001b[39m=\u001b[39m OneHotEncoder()\n\u001b[1;32m      3\u001b[0m labels \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mfit_transform(labels)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(labels\u001b[39m.\u001b[39;49mtoArray())\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/scipy/sparse/_base.py:771\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetnnz()\n\u001b[1;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(attr \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: toArray not found"
     ]
    }
   ],
   "source": [
    "labels = np.array(data[\"label\"].tolist()).reshape(-1, 1)\n",
    "encoder = OneHotEncoder()\n",
    "labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TYQoBAAPbAK1"
   },
   "source": [
    "### b) Universal Sentence Encoder\n",
    "Google's Universal Sentence Encoder ([USE](https://tfhub.dev/google/universal-sentence-encoder/4) [4]) is a convenient way to map any type of sentence to a 512-dimensional vector. In these 512-dimensional vectors semantic meaning is encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oYeA9OwTbAK1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 09:21:37.266841: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "# Run this code block only once as the download will take some time and embedding is very memory expensive!\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WymD6U7fbAK1"
   },
   "source": [
    "In this task you are suppossed to get a feeling for this type of embedding. Find a pair of sentences that are similar in their meaning but not syntactically. After that, think of two semantically very different sentences.\n",
    "Obtain the values for them and compare them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-dg6flX4bAK1"
   },
   "source": [
    "**TODO: Write your observations here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IsVjvYLobAK2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.01578294 -0.02893438  0.04538639 ...  0.032803   -0.02938719\n",
      "  -0.0648836 ]\n",
      " [ 0.00559102  0.02113481 -0.02073038 ... -0.01906953  0.0182902\n",
      "   0.01967947]\n",
      " [ 0.04504275  0.03873852  0.04591968 ... -0.00101801  0.00625382\n",
      "  -0.01690415]\n",
      " [ 0.02447147  0.03104402  0.01881739 ...  0.03276334 -0.00866744\n",
      "  -0.04828107]\n",
      " [ 0.04919384 -0.07159779  0.02107232 ... -0.03875272 -0.01441508\n",
      "   0.05322857]], shape=(5, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Try out USE here\n",
    "filtered_entries = data[data['text'].str.contains('men', case=False)]['text']\n",
    "print(embed(filtered_entries.values.tolist()[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9d_j-DwjbAK2"
   },
   "outputs": [],
   "source": [
    "# DONE: Now encode our dataset's tweets\n",
    "\n",
    "encoded_tweets = embed(data['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "k-RWP1FAbAK2"
   },
   "source": [
    "## Task 5.2: Base Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nR2HytxsbAK2"
   },
   "source": [
    "### a) Base Model creation\n",
    "In this code we create our base model and train it afterwards using the PyTorch library. We use a simple Neural Network to build this model. You can read about Neural Networks here in case you are not familiar with them.\n",
    "You can get a basic intuition for Neural Networks [here](https://medium.com/@shaistha24/basic-concepts-you-should-know-before-starting-with-the-neural-networks-nn-3-6db79028e56d) [5].\n",
    "\n",
    "For the base model we have our 512 dimensional input layer. Then we have a fully connected layer with 100 nodes and with a dropout rate of 0.5 is added. For now, you do not need to know what dropout is. After the dropout, another fully connected layer with 50 nodes is added and we once again add a 0.5 dropout rate.\n",
    "Our output layer has 3 nodes: One for \"sexism\", \"none\" and \"racism\". The computed values for these last 3 nodes correspond to the probability of belonging to either one of our categories."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "x32XCE3RbAK2"
   },
   "source": [
    "![title](./img/base_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zngyVOwzdv6l"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "ENCODING_DIM = 512\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(ENCODING_DIM, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHO6sHjr3rMv",
    "outputId": "42912f76-3421-4bb7-808a-6b4ada4c605b"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size = (0,512), batch_size = 32, device='cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3y-JP2SL45Cy"
   },
   "source": [
    "### b) Train-Test split for Base Model\n",
    "Splitting our labeled data into a train test and validation set is a common practice.\n",
    "* Train set: This set is used to train our model on. The model will try to learn from it.\n",
    "* Validation set: This set is used to choose hyper parameters. Since creating good models requires to find the right parameters (e.g. what kind of activation function, how many epochs etc.) this set is used to maximize the performance of a model for a fixed choice of parameters.\n",
    "* Test set: This set is used to evaluate our final model on. After the model has been trained and a final decision for hyper parameters has been made, the model will be evaluated on this set only. No more parameters should be changed after that.\n",
    "\n",
    "This rather strange seeming approach helps to identify models that actually generalize well and not just perform very good because we adapted the parameters to maximize the performance on one particular set.\n",
    "\n",
    "We will use 60% of our dataset to train our model (the train set) and the remaining 20% to evaluate our model (the test set)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PfkUVBhIIZfd"
   },
   "source": [
    "**Hint:** The sklearn library offers a function that could help you out with this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXW6xZoH45Cz",
    "outputId": "d141039e-f7b0-4aa7-fa80-b1a9d9a856ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (10109,), Labels shape: (10109, 3)\n",
      "Test data shape: (3370,), Labels shape: (3370, 3)\n",
      "Validation data shape: (3370,), Labels shape: (3370, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DONE: Split tweets and labels in Train/Test/Validation 60/20/20\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_tweets, labels, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training data shape: {}, Labels shape: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Test data shape: {}, Labels shape: {}\".format(X_test.shape, y_test.shape))\n",
    "print(\"Validation data shape: {}, Labels shape: {}\".format(X_val.shape, y_val.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cbMJFUqg5Xg7"
   },
   "source": [
    "In order to feed the data into the model, we must create Dataset objects for it, allowing the creation of Dataloaders. The Dataset retrieves both the features and labels of the data. While training a model, we want to feed the data in batches and reshuffle it at every epoch to reduce model overfitting. Dataloaders offer an API to do that process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "qCp0TtD3qr8J"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# DONE: Create a CustomDataset class for our Tweet data\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.encodings[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n",
    "\n",
    "# Create the Datasets\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader for batching and parallel data loading\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DJZFPf_WwGSO"
   },
   "source": [
    "### c) Train the Base Model\n",
    "\n",
    "**1.** Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bI2QIPUGexBa",
    "outputId": "ce6f7b2d-0634-4695-c21e-b38bb9b19093"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4341",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4341",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m val_steps \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     15\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     17\u001b[0m     inputs, labels \u001b[39m=\u001b[39m batch\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[23], line 17\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> 17\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencodings[idx]\n\u001b[1;32m     18\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels[idx]\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m x, y\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/miniconda3/envs/i2dl-assignments/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 4341"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "val_accuracy_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_steps = 0\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    val_steps = 0\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        _, val_labels = torch.max(outputs, dim=1)\n",
    "        val_acc += (val_labels == labels).sum().item() / labels.size(0)\n",
    "\n",
    "        val_steps += 1\n",
    "\n",
    "    train_loss_history.append(train_loss/train_steps)\n",
    "    val_loss_history.append(val_loss/val_steps)\n",
    "    val_accuracy_history.append(val_acc/val_steps)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Training loss={train_loss/train_steps}, validation loss={val_loss/val_steps}, validation accuracy={val_acc/val_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "fBzJMWw0xnuj",
    "outputId": "57ee30e3-1ba4-4f13-8513-120995eef6dc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_history, label='Train Loss')\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot validation categorical accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_accuracy_history, label='Validation Categorical Accuracy')\n",
    "plt.title('Validation Categorical Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V0lj4SWYbAK4"
   },
   "source": [
    "**2.** After you have looked at the graph, what do you think is an appropriate amount of `epochs`? Briefly explain at which amount of epochs the model seems to be underfitting or overfitting and how this depends on the learning rate?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GR9afmjh57P1"
   },
   "source": [
    "**TODO: Write your observations here**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "if8yjwQNwy_y"
   },
   "source": [
    "### d) Evaluate the Base Model\n",
    "\n",
    "The F1 score is a universal measurement of a test's accuracy. It is calculated as the harmonic mean of *precision* and *recall*.\n",
    "\n",
    "- **precision** refers to the number of true positives divided by the number of all positives\n",
    "- **recall** refers to the number of true positives divided by the number of relevant elements\n",
    "\n",
    "\n",
    "$$F_{1} = \\frac{2}{recall^{-1} + precision^{-1}} = \\frac{tp}{tp+\\frac{1}{2}(fp+fn)}$$\n",
    "\n",
    "where\n",
    "*   tp = true positives\n",
    "*   fp = false positives\n",
    "*   fn = false negatives\n",
    "\n",
    "**1.** Why would we prefer the F1 Score over only the precision?\n",
    "\n",
    "**2.** Evaluate the text model with an F1 score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4hRZ2e1DbAK4"
   },
   "source": [
    "**TODO 1: Write your explanation here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4OoPj1zw4kQ"
   },
   "outputs": [],
   "source": [
    "#from src.evaluation import f1_score_overall\n",
    "from evaluation import f1_score_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGsIDzD74VCg"
   },
   "outputs": [],
   "source": [
    "# Predicting the labels from the test set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(torch.tensor(test_dataset.encodings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dQkYnnTNw4au",
    "outputId": "e5b78ce0-6817-488b-d7ab-8dfec7445ad2"
   },
   "outputs": [],
   "source": [
    "# TODO 2: Evaluate text model\n",
    "# Hint: You can lookup the evaluation.py in the src folder for documentation\n",
    "\n",
    "f1_score_overall(y_test, y_pred, label_mapping=###)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xvegXhlxuUCN"
   },
   "source": [
    "## Task 5.3: Preprocessing for Social Model\n",
    "Now that we have evaluated our base model we can try to enhance it by using some sort of a social context. To do so, we are using our base model's prediction to compute an average hate score for each of the followers of an author. This means that for each author we take all his follower's tweets and predict the label. We then take the average of each prediction which results in our average hate score.\n",
    "\n",
    "For each tweet we then not only feed in the tweet itself, but also the hate score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "D4kmhJJT9Kpz"
   },
   "source": [
    "### Load adjacency matrix for users"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "w0YaL7CZJqpM"
   },
   "source": [
    "In order to create our social model, we first need to load the adjacency matrix. This matrix represents the follower network between all users that have written the 16849 tweets (crawled by Linda Jahn [6]). You can check the `extend_data.ipynb` file to find out how the adjacency matrix was created.\n",
    "\n",
    "The 16849 tweets were written by 2031 distinct users. This results in a 2031x2031 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXvkZYb_JXkg"
   },
   "outputs": [],
   "source": [
    "# Load users adjacency matrix\n",
    "users_adjacency_matrix = np.load(\"pickle_files/users_data/users_adjacency_matrix.npy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tHICY__D45Cp"
   },
   "source": [
    "### a) Graph visualization & manipulation\n",
    "Now we are going to plot the previously loaded adjacency matrix. Since we are going to feed the matrix to the Neural Network later, and because the user network is just a tiny subset of the whole Twitter network it is important to check if the network contains any useful information.\n",
    "\n",
    "\n",
    "**1.** Plot the graph corresponding to the given adjacency matrix.\n",
    "**Note:** For better visualization, the nodes are color-coded based on their degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfuRf30ommf7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rSv96Rqt45Cq",
    "outputId": "98a5b0e3-555e-4c95-c9c8-6eb6a06d93ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_graph(users_adjacency_matrix):\n",
    "\n",
    "    # TODO 1:\n",
    "\n",
    "    ###\n",
    "    \n",
    "    graph.add_edges_from(edges)\n",
    "\n",
    "\n",
    "    print(\"Total number of nodes:\", nx.number_of_nodes(graph))\n",
    "\n",
    "    from matplotlib.pyplot import figure\n",
    "    figure(num=None, figsize=(64, 50), dpi=100)\n",
    "    nx.draw(graph,\n",
    "            node_size=300,\n",
    "            node_color=range(nx.number_of_nodes(graph)),\n",
    "            cmap=plt.cm.Reds,\n",
    "            pos=nx.spring_layout(graph)\n",
    "           )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_graph(users_adjacency_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "j2DJp3GGkzz3"
   },
   "source": [
    "**2.** Briefly describe the graph. How many communities do you think it depicts?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xEIoD_U6Tr2u"
   },
   "source": [
    "**TODO 2: Write your observations here**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8F9-nJc8k8JI"
   },
   "source": [
    "**3.** Now let us try to actually calculate the number of communities within this graph. First, get rid of the uninteresting nodes that have zero or very few edges and just inspect the \"core\" graph. Expand on the code that you have written in the exercise above.\n",
    "**Hint**: You can do this by excluding all nodes with an `nx.eigenvector_centrality()` lower than $10^{-8}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sP3rrJEok-2z",
    "outputId": "488d5894-7526-4c28-a4d5-e23ec8423283"
   },
   "outputs": [],
   "source": [
    "def show_graph_core(users_adjacency_matrix):\n",
    "\n",
    "    # TODO 3:\n",
    "\n",
    "    ###\n",
    "    \n",
    "    graph.add_edges_from(edges)\n",
    "\n",
    "    print(\"Total number of nodes:\", nx.number_of_nodes(graph))\n",
    "\n",
    "    ###\n",
    "\n",
    "    print(\"Total number of significant nodes:\", nx.number_of_nodes(graph))\n",
    "\n",
    "    from matplotlib.pyplot import figure\n",
    "    figure(num=None, figsize=(64, 50), dpi=100)\n",
    "    nx.draw(graph,\n",
    "            node_size=1000,\n",
    "            node_color=range(nx.number_of_nodes(graph)),\n",
    "            cmap=plt.cm.Reds,\n",
    "            pos=nx.spring_layout(graph)\n",
    "           )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_graph_core(users_adjacency_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yxIMjFoImCFW"
   },
   "source": [
    "**4.** Do you think the social context could further improve our hate speech detection model? Find at least 2 pros and 2 cons."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "64zx0uLcbAK7"
   },
   "source": [
    "**TODO 4: Write your observations here**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "m67eUdbgbAK8"
   },
   "source": [
    "### b) Employment of our Base Model to predict the hatefulness of an author's followers\n",
    "\n",
    "Now that we have a trained model, we can use it to predict the hatefulness for any tweet. Therefore, we can use it to predict an average hate score for each follower of an author. This means that we predict the label for each tweet of an author's follower and then compute an average across all of these predictions.\n",
    "\n",
    "**1.** Predict all encoded tweets with the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyCKpMrNbAK8"
   },
   "outputs": [],
   "source": [
    "# TODO 1:\n",
    "\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "j9Vun92DbAK8"
   },
   "source": [
    "In the following code cell we load the authorship numpy array. It contains the author ID of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3myAb7_jIZKX"
   },
   "outputs": [],
   "source": [
    "# Loads authorship index\n",
    "authors_idx = np.load(\"pickle_files/users_data/authorship.npy\")\n",
    "authors_idx = np.reshape(authors_idx, newshape=(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mVnWuelvbAK8"
   },
   "source": [
    "**2.** Now for every tweet of our dataset we need to compute its authors hate score. Therefore:\n",
    " * First define a function `get_all_followers` that return all followers for a given user.\n",
    " * Then create a list `his_followers` that contains all followers for each user.\n",
    " * Now assign the hate predictions for each of all the followers tweets.\n",
    " * Finally in `user_avg_score` compute the hate score for each user by averaging out all his followers' tweets' hate scores. If there are no followers' tweets, assign our pre-computed average values `default_hate_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZUaBR2lbAK8"
   },
   "outputs": [],
   "source": [
    "default_hate_score = np.array([0.19446494, 0.75084399, 0.0546911])\n",
    "\n",
    "# TODO 2:\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9guRGbf8bAK8"
   },
   "outputs": [],
   "source": [
    "# Put authors' hate scores in the order of the tweets\n",
    "tweets_author_hate_score = list((map(lambda x: user_avg_score[int(x)], authors_idx)))\n",
    "\n",
    "tweets_author_hate_score = np.array(tweets_author_hate_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uj6T-8D9bAK8"
   },
   "source": [
    "## Task 5.4: Social Model\n",
    "\n",
    "Now that we have our social context prepared, we can build and train our Social Model using that information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yFUY_7bXbAK9"
   },
   "source": [
    "### a) Social Model creation\n",
    "\n",
    "With our social context we have 2 separate networks:\n",
    "* Our text network that processes the tweet (the same as the base model from before)\n",
    "* Our hate score network that basically decides how important the average hate score for the classification is\n",
    "\n",
    "Our 2 separate networks are concatenated and one last hidden layer with 100 nodes is added."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "j389MzycbAK9"
   },
   "source": [
    "![title](img/enhanced_model.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "g8VXwJ75bAK9"
   },
   "source": [
    "Now define our new neural network `social_model` according to the graphic above. You can lookup most of the syntax in exercise ***5.2 a)***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4URjY0TLQxW"
   },
   "outputs": [],
   "source": [
    "# TODO: Define the social model\n",
    "\n",
    "###\n",
    "\n",
    "# Create an instance of the social model\n",
    "encoding_dim = # Specify the encoding dimension\n",
    "social_model = SocialModel(encoding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1nUh5w5O4Bz"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(social_model.parameters(), lr=0.0005)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PNaZ21p_bAK9"
   },
   "source": [
    "### b) Train-Test split for Social Model\n",
    "Now split the data in Train/Val/Test 60/20/20 as seen in the Base Model. This time you have to create an additional set for the Hate Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tu9F4O52bAK9",
    "outputId": "966be4c7-af4f-43d6-8050-31af59cc7359"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "labels = factorized_labels[0]\n",
    "\n",
    "###\n",
    "\n",
    "print(\"Training data shape: {}, Labels shape: {}, Hate Score shape: {}\".format(X_train.shape, y_train.shape, a_train.shape))\n",
    "print(\"Test data shape: {}, Labels shape: {}, Hate Score shape: {}\".format(X_test.shape, y_test.shape, a_test.shape))\n",
    "print(\"Validation data shape: {}, Labels shape: {}, Hate Score shape: {}\".format(X_val.shape, y_val.shape, a_val.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JlE3px-gPYQx"
   },
   "source": [
    "Once again we need to create adequate Datasets and Dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFioOyu6PUju"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# TODO: Create a CustomDataset class for our Tweet data\n",
    "\n",
    "###\n",
    "\n",
    "# Create the Datasets\n",
    "train_dataset = ###\n",
    "val_dataset = ###\n",
    "test_dataset = ###\n",
    "\n",
    "# DataLoader for batching and parallel data loading\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "i3IKfEb3bAK9"
   },
   "source": [
    "### c) Train and Evaluate the Enhanced Model\n",
    "Once again, train and evaluate the model with a F1 Score. Use 20 `epochs` and `batch_size` of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0wWvi8jbAK-",
    "outputId": "110cb687-63c9-4129-c129-911547ac3a2c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "val_accuracy_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_steps = 0\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    val_steps = 0\n",
    "\n",
    "    social_model.train()\n",
    "    for inputs, hatescore, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = social_model(inputs, hatescore)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        train_steps += 1\n",
    "\n",
    "    social_model.eval()\n",
    "    with torch.no_grad():\n",
    "      for inputs, hatescore, labels in val_loader:\n",
    "        outputs = social_model(inputs, hatescore)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        _, val_labels = torch.max(outputs, dim=1)\n",
    "        val_acc += (val_labels == labels).sum().item() / labels.size(0)\n",
    "\n",
    "        val_steps += 1\n",
    "\n",
    "    train_loss_history.append(train_loss/train_steps)\n",
    "    val_loss_history.append(val_loss/val_steps)\n",
    "    val_accuracy_history.append(val_acc/val_steps)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Training loss={train_loss/train_steps}, validation loss={val_loss/val_steps}, validation accuracy={val_acc/val_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tjf6CQLObAK-",
    "outputId": "9c15b6e5-e534-4377-f2b7-15c2ca220f4c"
   },
   "outputs": [],
   "source": [
    "from src.evaluation import f1_score_overall\n",
    "\n",
    "# TODO: Evaluate the model with a F1 Score\n",
    "\n",
    "###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Brwe8cbSbAK-"
   },
   "source": [
    "## Task 5.5: Discussion and comparison\n",
    "\n",
    "* Compare the performances of our two models in your own words\n",
    "\n",
    "* Why do you think it improved?\n",
    "\n",
    "* Can you think of any other social context to further improve our model?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "c-VeHwtQbAK-"
   },
   "source": [
    "**TODO: Write your thoughts here**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "svmyf6kcbAK-"
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Festinger, L., Pepitone, A. and Newcomb, T. (1952) *Some Consequences of De-Individuation in a Group.* Journal of Abnormal and Social Psychology, 47, 382-389.\n",
    "<br>[2] Waseem, Z., & Hovy, D. (2016). *Hateful symbols or hateful people? Predictive features for hate speech detection on Twitter.* In Proceedings of the naacl student research workshop (pp. 88-93).\n",
    "<br>[3] https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html\n",
    "<br>[4] https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "<br>[5] https://pytorch.org/docs/stable/nn.html\n",
    "<br>[6] Jahn, L. (2020). *Leveraging Social Network Data for Hate Speech Detection.* Master\n",
    "Thesis, Technical University of Munich, Department of Informatics."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
